{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_df = pickle.load(open('./cui_df.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(set(indexes)) for indexes in cui_df['indexes']]\n",
    "cui_df['doc_count'] = lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(indexes) for indexes in cui_df['indexes']]\n",
    "cui_df['cui_count'] = lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_df.sort_values(by='doc_count', ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('hpo_ret_df2.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(df, cui_df):\n",
    "    tfidf_d = {}\n",
    "    total_docs = len(df)\n",
    "    count = 0\n",
    "    \n",
    "    # get rid of none values and replace with empty lists.\n",
    "    doc_ents = []\n",
    "    for ents in df['hpo_ents']:\n",
    "        if type(ents) == list:\n",
    "            doc_ents.append(ents)\n",
    "        else:\n",
    "            doc_ents.append([])  \n",
    "    df['hpo_ents'] = doc_ents\n",
    "    \n",
    "    for doc_ents in df['hpo_ents']:\n",
    "        holding_d = {}\n",
    "        counter_d = Counter(doc_ents)\n",
    "        doc_ent_counts = len(doc_ents)\n",
    "        for ent in doc_ents:\n",
    "            cui_i = cui_df.index[list(cui_df['hpo_str']).index(ent)]\n",
    "            # tf = number of terms in the doc / total num terms in the doc\n",
    "            term_freq = counter_d[ent] / doc_ent_counts\n",
    "            # DF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
    "            inv_doc_freq = np.log(total_docs / cui_df.loc[cui_i,'doc_count'])\n",
    "            tfidf = term_freq * inv_doc_freq\n",
    "            holding_d.update({ent:tfidf})\n",
    "        tfidf_d.update({df.index[count]:holding_d})\n",
    "        count+=1\n",
    "        \n",
    "    return tfidf_d, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply fcuntion to our dataframes\n",
    "tfidf_d, df = tfidf(df, cui_df)\n",
    "\n",
    "tfidf_df = pd.DataFrame.from_dict(tfidf_d, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_terms = {}\n",
    "for index, row in tfidf_df.iterrows():\n",
    "    top_ten = row.sort_values(ascending=False)[:10]\n",
    "    kws = list(top_ten.keys())\n",
    "    top_terms.update({index:kws})\n",
    "# lastly we'll add the df_ents to our paed_df and save it to file\n",
    "df['top_hpo'] = df.index.to_series().map(top_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import scispacy\n",
    "nlp = spacy.load('en_core_sci_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process a cui_df to rank the entity sentences by most interesting.\n",
    "# we are going to use the tfidf vectorizer and then normalize for number of entities in the sentence\n",
    "\n",
    "def tfidf_best_sents(cui_df):\n",
    "    \n",
    "    \n",
    "    # holding list for the top sentences for each term\n",
    "    top_sents = []\n",
    "    \n",
    "    # dummy funct for vectorizer\n",
    "    def dummy(ents):\n",
    "        return(ents)\n",
    "    \n",
    "    # import the tfidf vectorizer from sklearn\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    # instantiate with dummy funct for preprocessing and tokenization (we will already have the entities as a list)\n",
    "    tfidf_vectorizer = TfidfVectorizer(preprocessor = dummy, tokenizer = dummy, ngram_range = (1,1))\n",
    "\n",
    "    # iterate through the data frame, processing each term and term sentences\n",
    "    count = 0\n",
    "    for index, row in cui_df.iterrows():\n",
    "        # holding list for the spacy ents\n",
    "        ents = []\n",
    "        # set the term explicitly\n",
    "        term = row['hpo_str']\n",
    "        # set the sentences for that term\n",
    "        sents = row['sents']\n",
    "        # process each sentence, extracting the ents\n",
    "        # we can batch these to make it run a bit quicker\n",
    "        for doc in nlp.pipe(sents, batch_size = 500):\n",
    "            ents.append([str(ent) for ent in doc.ents])\n",
    "\n",
    "\n",
    "        # now we have the ents, lets make a tfidf_vector, one vector for each sentence\n",
    "        tfidf_vec = tfidf_vectorizer.fit_transform(ents)\n",
    "        # sum the values for the vecor\n",
    "        sums = [sum(vec) for vec in tfidf_vec.toarray()]\n",
    "        # normalise the tfidf sum using the number of ents in that sentence\n",
    "        norm_sum = [a / b for a, b in zip(sums, [len(ent_list) for ent_list in ents])]\n",
    "        \n",
    "        # build a dataframe to sort by norm sum\n",
    "        df = pd.DataFrame(data={'sents':sents, 'ents':ents, 'sums':sums, 'norm_sum':norm_sum})\n",
    "        \n",
    "        # do the subset for sents with at least 4 entites present \n",
    "        condition = [len(ents) >= 4 for ents in df['ents']]\n",
    "        df = df.loc[condition, :]\n",
    "        \n",
    "        # sort by largest normalised tfidf sum\n",
    "        df.sort_values(by = 'norm_sum', ascending = False, inplace = True)\n",
    "        # pick the top ten sentences\n",
    "        df = df.head(10)\n",
    "        # add these sentences to the cui dataframe\n",
    "        top_sents.append(list(df['sents']))\n",
    "        count +=1\n",
    "        \n",
    "        if count%100 ==0:\n",
    "            print(f'{count} of {len(cui_df)}')\n",
    "    cui_df['top_sents'] = top_sents\n",
    "        \n",
    "    return cui_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_df = tfidf_best_sents(cui_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cui_df, open('./cui_df.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Severe\n",
      "negations = 0.094\n",
      "Trigger: Counter({'severe': 5878, 'Severe': 300, 'S. Severe': 3, 'Severe 7': 1, 'M. Severe': 1})\n",
      "Severe and critical cases were indicated for intensive care unit (ICU) admission.\n",
      "Severe complications of the disease were not observed in any of the patients.\n",
      "Severe patients, that is, those requiring ICU, represented 44% of the cohort (n=7).\n",
      "Severe dyspnea demanded the emergency use of an oxygen face mask.\n",
      "Rhabdomyolysis in a Patient with Severe Hypothyroidism.\n",
      "Severe and critical cases were , , , , and for the age groups, < 1, 1 to 5, 6 to 10, 11 to 15, and >= 16 years, respectively.\n",
      "Severe cases were significantly more common among men than women.\n",
      "Nevertheless, there were still two severe cases of COVID-19 among these five patients.\n",
      "Severe COVID-19 in children is rare.\n",
      "Severe SIADH has previously been observed in a few adults with SARS-CoV-2 pneumonia [].\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Fever\n",
      "negations = 0.125\n",
      "Trigger: Counter({'fever': 4116, 'Fever': 260, 'pyrexia': 22, 'hyperthermia': 8, 'Pyrexia': 3, 'fever KD': 1, 'Q fever': 1, 'Fever>4': 1, 'Hyperthermia': 1, 'Fever 13': 1, 'Fever 116': 1, 'fever(+': 1, 'Fever 11': 1, 'fever’': 1, 'Fever>=': 1, '’s fever': 1, 'fever Fever': 1, '– fever': 1})\n",
      "Fever was the most common symptom (46, 82%), followed by respiratory symptoms (33, 59%), and gastrointestinal symptoms (31, 55%).\n",
      "Fever was the most common symptom (46, 82%), followed by respiratory symptoms (33, 59%), and gastrointestinal symptoms (31, 55%).\n",
      "Fever was the most common symptom (46, 82%), followed by respiratory symptoms (33, 59%) and gastrointestinal symptoms (31, 55%) (Table 2 ).\n",
      "His fever was 38°C and oropharyngeal and left tympanic membrane hyperaemia were noticed during his physical examination.\n",
      "Fever, diarrhea, shock and rash were also found.\n",
      "His fever resolved and weaned off vasoactive infusions by hospital day 5.\n",
      "Fever along with rash or diarrhea are common presenting symptoms .\n",
      "Fever and rash were the first presenting symptoms in our case.\n",
      "Apart from hyperthermia, at least four of the five major clinical features are required for complete and less than four for an incomplete form of KD .\n",
      "Fever was present in 14 children (), anosmia in three (), and vomiting in two ().\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Increased mean corpuscular volume\n",
      "negations = 0.076\n",
      "Trigger: Counter({'increased': 4088, 'Increased': 127, 'Increasedc': 1})\n",
      "Increased financial difficulty was also regarded as a possible risk factor for mental health.\n",
      "Increased acute phase reactants and coagulation disorders were a common characteristic at blood tests.\n",
      "Increased treatment adherence during the pandemic could have also contributed.\n",
      "Increased awareness of intensive follow-up after discharge are also of utmost importance.\n",
      "B1 Lung window: Increased of lung markings.\n",
      "Increased expenses since the start of the outbreak seemed to be most prominently related to food.\n",
      "almost no changeb) Increasedc (, ) (, ) (, ) Decreased (, ) (, ) (, ) Change in time spent working at home (ref.\n",
      "It is increased in patients with severe COVID-19 .\n",
      "In December 2011 this increased to include all children under the age of 18 years.\n",
      "Their prevalence at baseline was (203/2489), which was the same as a whole, and increased during 4 months (p=).\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Mild\n",
      "negations = 0.075\n",
      "Trigger: Counter({'mild': 1928, 'Mild': 56, 'mild PA': 7, 'mild 13': 1, 'mild 8': 1, 'Mild Mild ED': 1, 'C. Mild': 1, 'Mild 41': 1, 'mild AB': 1})\n",
      "DISCUSSION The symptoms of children confirmed with COVID-19 are mostly mild .\n",
      "30 () patients were asymptomatic; 142 () had mild or moderate disease.\n",
      "Of these, a majority (339, ) had mild to moderate symptoms or were asymptomatic.\n",
      "All patients but one experienced asymptomatic to mild symptoms.\n",
      "Eleven cases were classified as mild or moderate and one as severe.\n",
      "Eleven cases were classified as mild or moderate and one as severe.\n",
      "COVID-19 disease is usually mild in children.\n",
      "This means that about 90% of the children in this study had a mild or moderate disease.\n",
      "It started around the same time as the onset of fever and was of mild severity continually occurring throughout the day.\n",
      "Overall, disease in infants with SARS-CoV-2 was mild.\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Coughing\n",
      "negations = 0.139\n",
      "Trigger: Counter({'cough': 1479, 'coughing': 99, 'Cough': 23, 'Coughing': 7, '’s cough': 1})\n",
      "Coughing and nasal discharge began the day before admission.\n",
      "Cough was the most common symptom (n = 130, 45%), followed by upper respiratory tract infection (n = 93, ) and sore throat (n = 31, ).\n",
      "She had signs of large airway obstruction and increasing coughing but was apyrexial.\n",
      "Physiotherapy was started to stimulate coughing and later to support his muscle weakness.\n",
      "Transmission of the virus occurs mostly through coughing and close contact.\n",
      "She had experienced coughing and sore throat during the previous week and complained of muscle weakness.\n",
      "Cough (52 %), headache (43 %), and sore throat (36 %) were the most common symptoms.\n",
      "Other symptoms included cough (n = 19, 40%), fatigue (n = 8, 17%), and diarrhea (n = 5, 10%).\n",
      "Other common symptoms were cough and sore throat, present in about 20% of children.\n",
      "The most common symptoms of the patients were fever and cough (Table ).\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(row['hpo_str'])\n",
    "    print(f'negations = {np.round(sum(row[\"negation\"])/len(row[\"negation\"]),3)}')\n",
    "    print(f'Trigger: {Counter(row[\"triggers\"])}')\n",
    "    for sent in row['top_sents']:\n",
    "        print(sent)\n",
    "    print('\\n\\n-------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gopher]",
   "language": "python",
   "name": "conda-env-gopher-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
